import os
import pandas as pd
import datetime
import snscrape.modules.twitter as sntwitter
from textblob import TextBlob

# é…ç½®
KEYWORDS = ["AI", "äººå·¥æ™ºèƒ½", "ChatGPT"]  # é‡‡é›†å…³é”®è¯
MAX_TWEETS_PER_RUN = 200
DATA_FILE = "tweets_dataset.csv"

# è¯»å–å†å²æ•°æ®
if os.path.exists(DATA_FILE):
    df_existing = pd.read_csv(DATA_FILE)
else:
    df_existing = pd.DataFrame(columns=["date", "id", "content", "username"])

# é‡‡é›†
tweets_list = []
today = datetime.date.today()

for keyword in KEYWORDS:
    query = f"{keyword} since:{today - datetime.timedelta(days=1)} until:{today}"
    for i, tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):
        if i >= MAX_TWEETS_PER_RUN:
            break
        tweets_list.append([tweet.date, tweet.id, tweet.content, tweet.user.username])

# ä¿å­˜ & åˆå¹¶
df_new = pd.DataFrame(tweets_list, columns=["date", "id", "content", "username"])
df_all = pd.concat([df_existing, df_new]).drop_duplicates(subset="id", keep="first")
df_all.to_csv(DATA_FILE, index=False, encoding="utf-8")

print(f"âœ… é‡‡é›†å®Œæˆï¼Œæœ¬æ¬¡æ–°å¢ {len(df_new)} æ¡æ¨æ–‡ï¼Œæ€»æ•°ï¼š{len(df_all)} æ¡")

# åˆ†æ
df_all["sentiment"] = df_all["content"].apply(lambda x: TextBlob(x).sentiment.polarity)
avg_sentiment = df_all["sentiment"].mean()
print(f"ğŸ“Š å¹³å‡æƒ…ç»ªå€¾å‘ï¼š{avg_sentiment:.2f}")
